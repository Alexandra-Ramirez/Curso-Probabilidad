\documentclass[a4paper,11pt]{report}
\usepackage[sc]{mathpazo}
%\usepackage[light,firsttwo,outline,bottomafter]{draftcopy}
%\usepackage{srcltx}
\usepackage{anysize} % Soporte para el comando \marginsize
\marginsize{1.2cm}{1.2cm}{1cm}{1cm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[latin1]{inputenc}
\usepackage[english,spanish]{babel}
\usepackage{amsmath}
\usepackage{multicol} 
\columnsep=7mm
\usepackage{latexsym}
\usepackage{mathrsfs}
\usepackage{bigints}
\usepackage{indentfirst}
\usepackage{graphicx}
\usepackage{enumitem}
%\usepackage{hyperref}

\usepackage{times}



%\usepackage{xcolor}
%\usepackage{pgfplots}
%\usepackage{tikz}

%
%\definecolor{bblue}{HTML}{4F81BD}
%\definecolor{rred}{HTML}{C0504D}
%\definecolor{ggreen}{HTML}{9BBB59}
%\definecolor{ppurple}{HTML}{9F4C7C}


\setlength{\paperwidth}{216mm} \setlength{\paperheight}{230mm}
\setlength{\textwidth}{39pc} \setlength{\textheight}{57.5pc}
\setlength{\topmargin}{-1.5cm} \setlength{\oddsidemargin}{-0.5cm}
\setlength{\evensidemargin}{0.9cm}
%\setlength{\footskip}{-0.3cm}

\newcommand{\ds}{\displaystyle}
\newcommand{\normal}{\triangleleft \,}
\newcommand{\tx}{\textrm}
% \linespread{1.2} \sloppy


\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\PR}{\mathbb{P}}
\newcommand{\e}{\rightarrow}
\newcommand{\bi}{\Leftrightarrow}
\newcommand{\com}{\mathbb{N} \bi}
\newcommand{\fu}{f:\N \e \R}
\newcommand{\ba}{\backslash}
\newcommand{\Q}{\mathbb{Q}}


\newcommand{\calP}{\mathcal{P}}
\newcommand{\calF}{\mathcal{F}}
\newcommand{\calL}{\mathcal{L}}


\newcommand{\ovl}{\overline}
\newcommand{\ora}{\overrightarrow}
\newcommand{\ola}{\overleftarrow}
\newcommand{\olra}{\overleftrightarrow}{\tiny }
\newcommand{\ula}{\underleftarrow}
\newcommand{\ura}{\underrightarrow}


\newcommand{\inner}[2]{\langle{#1},{#2}\rangle}


\begin{document}
\begin{center}
	{\LARGE\textbf {Preguntas de repaso de Introducci\'on a los Procesos Estoc\'asticos}}
\end{center}

\setlength{\unitlength}{1in}

\begin{picture}(6,.1) 
\put(0,0) {\line(1,0){6.25}}         
\end{picture}
\vspace{0.8cm}

\vspace{0.2cm}
	
	\renewcommand{\arraystretch}{2}
	
	\vskip.25in
	
	\noindent {\Large \textbf{Lista de Problemas}} 
	
	\vskip.25in

%\begin{multicols}{1}

 \vspace{0.3cm}
 
\begin{enumerate}
\item Si $X \sim N(\mu, \sigma^2)$ entonces $Y = \alpha X + \beta \sim N(\alpha \mu , \alpha^2\sigma^2)$.
\item 

\begin{enumerate}
	\item Si  $X \sim \text{Bernoulli}(p)$, entonces  $\mathbb{E}(X) = p$.
	\item Si  $X \sim \text{Binom}(n,p )$ entonces $\mathbb{E}(X) = np$.
	\item Si $X \sim \text{Geom}(p)$ entonces  $\mathbb{E}(X) = \frac{1}{p}$.
	\item Si  $X \sim \text{Poisson}(\lambda)$ entonces $\mathbb{E}(X) = \lambda$.
	\item Si $X \sim \text{Uniform}((\alpha, \beta))$ entonces $\mathbb{E}(X) = \frac{\beta + \alpha}{2}$.
	\item Si $X \sim \text{Uniform}((\alpha, \beta))$ entonces $\mathbb{E}(X) = \frac{\beta + \alpha}{2}$.
	\item Si $X \sim \text{Exponential}(\lambda )$ entonces $\mathbb{E}(X) = \frac{1}{\lambda}$.
	\item Si $X \sim N(\mu, \sigma^2)$ entonces  $\mathbb{E}(X) = \mu$.
	\item Si  $X \sim \Gamma(\alpha, \lambda)$ entonces $\mathbb{E}(X) = \frac{\alpha}{\lambda}$.
\end{enumerate}
\item 

\begin{enumerate}
	\item Si $X$ es una variable aleatoria discreta con \textit{pmf} $p(x)$, entonces para una funci\'on $g$
	
	\[
	\mathbb{E}[g(X)] = \sum_{x:p(x) > 0}g(x)p(x).
	\]
\item Si $X$ es una variable aleatoria continua con \textit{pmf} $f(x)$, entonces para una funci\'on $g$ de valor real
\[
\mathbb{E}[g(X)] = \bigintss_{-\infty}^{\infty}g(x)f(x) dx.
\]
	\item Si $a$ y $b$ son constantes, entonces
	
	\[
	\mathbb{E}[aX + b] = a\mathbb{E}(X)  + b
	\]
\end{enumerate}
\item

\begin{enumerate}
\item  Si $X \sim N(\mu, \sigma^2)$ entonces $\mathbb{Var}(X) = \sigma^2$.
\item Prueba que 

\[
\mathbb{Var}(X) = \mathbb{E}(X^2) - \mathbb{E}(X)^2
\]
\end{enumerate}
\item 

\begin{enumerate}
\item Si $X$ e $Y$ son variables aleatorias continuas, entonces $\mathbb{E}(X + Y ) = \mathbb{E}(X) + \mathbb{E}(Y)$.
\item Sea $X_i$ una variable aleatoria tal que 

\[
X_i = \begin{cases}
1, & \text{i-\'esimo lanzamiento es un \'exito}\\
0, & \text{i-\'esimo lanzamiento es una falla}
\end{cases}
\]

Calcula $\mathbb{E}(X)$ donde $X = X_1 +X_2 + \dots + X_n$. ($X \sim \text{Binom}(n,p )$ ).
\end{enumerate}
\item 

\begin{enumerate}
	\item Si $X$ e $Y$ son independientes, entonces para dos funciones $f$ y $g$ se tiene
	
	\[
	\mathbb{E}(g(X)h(Y)) = \mathbb{E}(g(X))\mathbb{E}(h(Y))).
	\]
\end{enumerate}

\item

\begin{enumerate}
	\item (Desigualdad de Markov) Si $X$ es una variable aleatoria de valores positivos, entonces para un $a > 0$
	
	\[
	\PR(X \geq a) \leq \frac{\mathbb{E}(X)}{a}
	\]
\item (Desigualdad de Chebyshev) Si $X$ es una variable aleatoria con media $\mu$ y varianza $\sigma^2$, entonces para alg\'un $k > 0$

\[
\PR\{\vert X - \mu \vert \geq k  \} \leq \frac{\sigma^2}{k^2}
\]
\end{enumerate}

\item Considera la densidad gamma con par\'ametros $\alpha$ y $\lambda$

\[
\frac{\lambda e^{-\lambda t}(\lambda t)^{\alpha -1}}{\Gamma(\alpha)}.
\]

donde $\Gamma(\alpha)$ es de la forma $\Gamma(\alpha) = \bigintss_{0}^{\infty}e^{-x}x^{\alpha - 1}dx $. Prueba

\begin{itemize}
	\item $\Gamma(1) =  1$
	\item $\Gamma(\alpha ) = (\alpha - 1)\Gamma(\alpha - 1)$
	\item $\Gamma(k) = (k - 1)!$ si $k$ es entero.
	\item $\Gamma(\frac{1}{2}) = \sqrt{\pi}$.
\end{itemize}

\item Si $X_1$ y $X_2$ del tipo binomial independientes con param\'etros  $(n_1, p)$ y $(n_2, p)$ respectivamente, sea $q = 1 - p$, entonces calcula

\[
\PR(X_1 = k| X_1 + X_2 = m)
\]


\item Sea $N_t$ el n\'umero de llegadas en el intervalo $[0, t]$ cuyo \textit{pmf} es

\[
\PR(N_t = k) = e^{-\lambda t}\frac{(\lambda t)^k}{k!}
\]

para $k \geq 0$, tal que $\mathbb{E}(N_t) = \lambda t$. Asumimos que los $N_t$ son igual de espaciados  en el intervalo de tiempo. Sea $T_k$ en el k-\'esima llegada. Halla $F_{T_k}$ y $f_{T_{k}}, \mathbb{E}(T_k)$ , $\mathbb{E}(T_k^2)$ y $\mathbb{Var}(T_k)$.


\item Prueba que para toda variable $X$ e $Y$

\[
\mathbb{E}(X) = \mathbb{E}(\mathbb{E}(X| Y))
\]

Especificamente, si $Y$ es discreta,

\[
\mathbb{E} = \sum_{y}\mathbb{E}(X|Y = y)\PR(Y = y)
\]

y si $Y$ es continua con \textit{pdf} $f_{Y}(y)$ entonces

\[
\mathbb{E}(X) = \bigintss_{-\infty}^{\infty}\mathbb{E}(X|Y_0=y)f_{Y}(y)dy
\]


\item Prueba

\[
\mathbb{Var}(X) = \mathbb{E}(\mathbb{Var}(X | Y)) + \mathbb{Var}(\mathbb{E}(X|Y))
\]
\item Sea $N$ el n\'umero de accidentes por semana y sea $X_i$ el n\'umero de heridos en el i-\'esimo accidente. Asume que $X_i$ y $N$ son independientes y que $X_i$ son id\'enticamente distribuidas. ?` Cu\'al es la media esperada del n\'umero de heridos?.

\vspace{0.2cm}

Este es un ejemplo de \textit{variable aleatoria compuesta } $\sum_{i=1}^{N}X_i$, la suma de una variable aleatoria $N$ de variables id\'enticamente distribuidas e independientes que son independientes de $N$
\item  Supongamos que $X$ e $Y$ son independientes con \textit{pdfs} $f_X$ y $f_Y$. Calcula $\PR(X < Y)$.

\item Sea $X_1, \dots X_n$ variables aleatoria de Bernoulli, donde cada $X_i$ tiene param\'etro $p_i$. Es de decir $\PR(X_i = 1) = p_i$ y $\PR(X_i = 0) = q_i = 1 -p_i$

Si 

\[
P_{k}(j) = \PR(X_1 +X_2 + \cdots X_k = j)
\]

Prueba

\[
P_{k}(j) = p_kP_{k -1}(j -1) + q_kP_{k -1}(j).
\]


\item Sea $X$ una variable exponencial con param\'etro $\lambda$. Prueba

\[
\mathbb{E}(X| X > t) = t + \frac{1}{\lambda}.
\]

\item Sean $X_1, X_2\dots $ variables \texttt{i.i.d} con $\mathbb{E}(X_i) = \mu$ y $\mathbb{Var}(X_i) = \sigma ^2$ para cada $i$. Sea $N$ una variable aleatoria de $X_i$, con $\mathbb{E}(N) = a$ y $\mathbb{Var}(N) = b^2$. Definimos $S = \sum_{1}^{N}X_i$ para $N \geq 1$ y $S = 0$ para $N = 0$. Halla

\begin{enumerate}
	\item $\mathbb{E}(S)$
	\item $\mathbb{E}(S^2)$
	\item $\mathbb{Var}(S)$
\end{enumerate}
\item Sea $N$ pruebas con probabilidad de \'exito $p$ y sea $N \sim \text{Poisson}(a)$. Sea $L$ y $M$ el n\'umero de \'exitos y fallas respectivamente. Sea $X_i$ un indicador de \'exitos,e esto es $\PR(X_i = 1) = p$ y $\PR(X_i = 0) = 1 - p = q$. Sea $L = \sum_{i =1}^{N}X_i$. Prueba

\[
\PR(L =i, M =j) = \frac{e^{-ap}(ap)^i}{i!}\frac{e^{-aq}(aq)^j}{j!} \ \ p + q = 1
\]

\item Si el sol sale durante $n$ d\'ias consecutivos, ?`cu\'al es la probabilidad de que salga ma\~nana, si sabemos que salga o no es una variable aleatoria de Bernoulli?.
\end{enumerate}

\begin{flushright}
%\\{\bfseries El profesor.}
\footnote{Hecho en \LaTeX}
\end{flushright}

\end{document}
