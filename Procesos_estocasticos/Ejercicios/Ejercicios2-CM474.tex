\documentclass[a4paper,11pt]{report}
\usepackage[sc]{mathpazo}
%\usepackage[light,firsttwo,outline,bottomafter]{draftcopy}
%\usepackage{srcltx}
\usepackage{anysize} % Soporte para el comando \marginsize
\marginsize{1.2cm}{1.2cm}{1cm}{1cm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[latin1]{inputenc}
\usepackage[english,spanish]{babel}
\usepackage{amsmath}
\usepackage{multicol} 
\columnsep=7mm
\usepackage{latexsym}
\usepackage{mathrsfs}
\usepackage{bigints}
\usepackage{indentfirst}
\usepackage{graphicx}
\usepackage{enumitem}
%\usepackage{hyperref}

\usepackage{times}



%\usepackage{xcolor}
%\usepackage{pgfplots}
%\usepackage{tikz}

%
%\definecolor{bblue}{HTML}{4F81BD}
%\definecolor{rred}{HTML}{C0504D}
%\definecolor{ggreen}{HTML}{9BBB59}
%\definecolor{ppurple}{HTML}{9F4C7C}


\setlength{\paperwidth}{216mm} \setlength{\paperheight}{230mm}
\setlength{\textwidth}{39pc} \setlength{\textheight}{57.5pc}
\setlength{\topmargin}{-1.5cm} \setlength{\oddsidemargin}{-0.5cm}
\setlength{\evensidemargin}{0.9cm}
%\setlength{\footskip}{-0.3cm}

\newcommand{\ds}{\displaystyle}
\newcommand{\normal}{\triangleleft \,}
\newcommand{\tx}{\textrm}
% \linespread{1.2} \sloppy


\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\PR}{\mathbb{P}}
\newcommand{\e}{\rightarrow}
\newcommand{\bi}{\Leftrightarrow}
\newcommand{\com}{\mathbb{N} \bi}
\newcommand{\fu}{f:\N \e \R}
\newcommand{\ba}{\backslash}
\newcommand{\Q}{\mathbb{Q}}


\newcommand{\calP}{\mathcal{P}}
\newcommand{\calF}{\mathcal{F}}
\newcommand{\calL}{\mathcal{L}}


\newcommand{\ovl}{\overline}
\newcommand{\ora}{\overrightarrow}
\newcommand{\ola}{\overleftarrow}
\newcommand{\olra}{\overleftrightarrow}{\tiny }
\newcommand{\ula}{\underleftarrow}
\newcommand{\ura}{\underrightarrow}


\newcommand{\inner}[2]{\langle{#1},{#2}\rangle}


\begin{document}
\begin{center}
	{\LARGE\textbf {Preguntas de Introducci\'on a los Procesos Estoc\'asticos}}
\end{center}

\setlength{\unitlength}{1in}

\begin{picture}(6,.1) 
\put(0,0) {\line(1,0){6.25}}         
\end{picture}
\vspace{0.8cm}

\vspace{0.2cm}
	
	\renewcommand{\arraystretch}{2}
	
	\vskip.25in
	
	\noindent {\Large \textbf{Lista de Problemas}} 
	
	\vskip.25in

%\begin{multicols}{1}

 \vspace{0.3cm}
 
\begin{enumerate}
\item Una \textit{funci\'on generadora} de una secuencia de n\'umeros reales $a = \{ a_i: i = 0, 1, 2, \dots\}$ es definida como $G_a$

\[
G_a(s) = \sum_{i = 0}^{\infty}a_is^i
\]

para $s \in \mathbb{R}$ donde la suma converge.


\vspace{0.3cm}

La \textit{convoluci\'on} de una secuencia real $a = \{ a_i: i = 0, 1, 2, \dots\}$ y $b = \{b_i: i \geq 0 \}$ es la secuencia $c = \{c_i: i \geq 0  \}$, definida por

\[
c_n = a_0b_n + a_1b_{n -1} + \cdots + a_nb_{0}
\]

y se escribe como $c = a* b$

\begin{enumerate}
	\item Si $a$ y $b$ tienen funciones generadoras $G_a$ y $G_b$, entonces la funci\'on generadora de $c$ es
	
	\[
	G_{c}(s) = G_{a}(s)G_{b}(s)
	\]
	
	\item Prueba la identidad combinatoria 
	
	\[
	\sum_{i}\binom{n}{i}^2 = \binom{2n}{n}
	\]
\end{enumerate}

\item La \textit{funci\'on generadora de probabilidad}  de una variable aleatoria $X$ es definida como la funci\'on generadora $G(s) = \mathbb{E}(s^X)$ de su funci\'on de masa de probabilidad. Por ser una serie de potencias

\begin{enumerate}
	\item Existe un \textit{radio de convergencia $R (\geq 0)$} tal que la suma converge absolutamente si $\vert s \vert  < R$ y diverge si $\vert s \vert > R$. La suma converge uniformemente  sobre los conjuntos  de a forma $\{s: \vert s \vert \leq R^{'} \}$ para $R^{'} < R$.
	\item $G_a(s)$ puede ser derivable o integrable t\'ermino a t\'ermino alg\'un n\'umero de veces en el punto $s$ satisfaciendo $\vert s \vert  < R$.
	\item Si $G_a(s) = G_b(s)$  para $\vert s \vert  < R^{'}$ donde $0  < R^{'} \leq R$ entonces $a_n = n_n$ para todo $n$. Adem\'as 
	
	\[
	a_n = \frac{1}{n!}G_{a}^{(n)}(0).
	\]
\item Si $a_i \geq 0$ para todo $i$ y $G_{a}(s)$ es finito para $\vert s \vert < 1$, entonces $\lim_{s \rightarrow 1^{+}}G_{s} = \sum_{i = 0}^{\infty}a_i$ si la suma es finita o igual a $\infty$.

\end{enumerate}


Prueba lo siguiente

\begin{enumerate}
	\item Si $X$ tiene una funci\'on generadora $G(s)$ entonces
	
	\begin{itemize}
		\item $\mathbb{E}(X) = G^{'}(1)$.
		\item  En general $\mathbb{E}(X)[X(X -1)\dots (X - k + 1)] = G^{k}(1)$.
	\end{itemize}
\item Si $X$ e $Y$ son independientes entonces $G_{X + Y }(s)  = G_{X}(s)G_{Y}(s)$.
\item Si $X_1, X_2, \dots, X_n$ son variables aleatorias independientes de Bernoulli, con param\'etro $p$, con suma $S = X_1 + X_2 + \cdots + X_n$. Prueba que

\[
G_S(s) = (q + ps)^n \ \ \ p +  q = 1
\]

En general prueba que la suma $S = X_1 + X_2 + \cdots X_n$ de variables independientes tomando valores no negativos tiene una funci\'on generadora  dada por

\[
G_S = G_{X_1}G_{X_2}\dots G_{X_n}.
\]
\end{enumerate}

\item Si $X_1, X_2, \dots $ es una secuencia de variables aleatorias independientes  identic\'amente distribuidas como una funci\'on generadora com\'un $G_X$ y $N \geq 0$ es una variable aleatoria que es independiente de las variables  $X_i$ y tiene una funci\'on generadora  $G_N$, entonces $S = X_1 + X_2 + \cdots X_N$ tiene una funci\'on generadora dada

\[
G_{S}(s) = G_{N}(G_{X}(s))
\]

\item Se define \textit{funci\'on generadora de momentos} de una variable aleatoria $X$ a $M_X = G_X(e ^t)$ 

\begin{enumerate}
	\item Prueba que para una variable aleatoria Poisson de param\'etro $\lambda$ se tiene
	
	\[
	M(t) = \exp(\lambda (e^t - 1)).
	\]
	
	\item Sea $p_r > 0$ y $a_r \in \mathbb{R}$ para $1 \leq r \leq n$. ?` Cu\'al  de las siguientes expresiones es una funci\'on generadora de momentos y para que variable aleatoria?
	
	\[
	M(t) = 1 + \sum_{r = 1}^{n}p_rt^r \ \ \ M(t) = \sum_{r = 1}^{n}p_re^{a_rt}.
	\]
	\item Sea $X$ una variable aleatoria geom\'etrica con param\'etro $p$. Muestra que la funci\'on generadora de momentos de $X$, es dada por 
	
	\[
	M_X(t) = \frac{pe^t}{1 - qe^t}, \ \ \ q =  1 -p, \ \ t < -\ln q
	\]
	
	Usa $M_{X}(t)$ para encontrar $\mathbb{E}(X)$ y $\mathbb{Var}(X)$.
	
	\item Sea $Z \sim N(0,1)$. Usa $M_Z(t) = e^{t^2/2}$ para calcular $\mathbb{E}(Z^N)$, donde $n$ es un n\'umero positivo.
\end{enumerate}

\item Sean $X$ e $Y$ variables aleatorias binomiales independientes con param\'etros $(n , p)$ y $(m, p)$ respectivamente. Calcula

\[
\mathbb{P}( X = i | X + Y = j)
\]

e interpreta el resultado.

\item Un ascensor puede transportar hasta $3.500$ libras. El fabricante ha incluido un margen de seguridad de $500$ libras y  lista la capacidad  en $3000$ libras. La administraci\'on del edificio busca evitar accidentes al limitar el n\'umero de pasajeros en el ascensor. Si el peso de los pasajeros que utilizan el ascensor es $N(155, 625)$, ?`cu\'al es el n\'umero m\'aximo de pasajeros que pueden utilizar el ascensor si las probabilidades de exceder la capacidad nominal de $3000$  libras ha de ser mayor que $10.000$ a $3$?.



\item Supongamos que un \texttt{mono inmortal} est\'a constantemente escribiendo en un procesador de textos que no es fr\'agil, dura para siempre, y tiene memoria infinita. Supongamos que el teclado del procesador de textos tiene $m-1$ teclas, una barra de espacio para los espacios en blanco, y una tecla distinta para diferentes s\'imbolos. Si cada vez que el mono presiona uno de los $m$ s\'imbolos (incluyendo la barra espaciadora) al azar, y si al final de cada l\'nea y al final de cada p\'agina el  procesador de textos avanza  una nueva l\'inea y una nueva p\'agina por s\'i mismo, ?` cu\'al es la probabilidad de que el mono llegue  a producir las obras completas de Shakespeare en orden cronol\'ogico y sin errores?.

\item En un gran aeropuerto internacional, un banco de cambio de divisas con un solo cajero est\'a abierto las $24$ horas del d\'ia, 7 d\'ias a la semana. Supongamos que en alg\'un tiempo $t = 0$, el banco est\'a libre de  clientes y  nuevos clientes llegan en momentos aleatorios $T_1, T_1 + T_2, T_1 + T_2 + T_3, \dots $ Donde $T_1, T_2, T_3,\dots $ son variables aleatorias  id\'enticamente distribuidas y  independientes con $\mathbb{T_i} = 1 / \lambda$. Cuando el cajero est\'a libre, el tiempo de servicio de un cliente que entra en el banco comienza a su llegada.

De lo contrario, el cliente se une a la cola y espera para ser atendido en un primer momento para  dejar el banco despu\'es de ser atendido. Si el tiempo de servicio  del i-\'esimo cliente es  $S_i$, donde $S_1, S_2, S_3,\dots $ son variables aleatorias id\'enticamente distribuidas y  independientes con $\mathbb{E}(S_i) = 1/\mu $. 

Muestra que si $\lambda < \mu $  entonces con probabilidad $1$, eventualmente, para un  periodo,  el banco deber\'ia no tener  de clientes de nuevo.


\item Sea la funci\'on de masa de probabilidad conjunta de $X_1, X_2, \dots, X_r$ multinomial, es decir

\[
p(x_1, x_2, \dots, x_r) = \frac{n!}{x_1!x_2!\cdots x_r!}p_1^{x_1}p_{2}^{x_2}\cdots p_r^{x_r},
\]

donde $x_1  + x_2 + \cdots + x_r = n$ y $p_1 + p_2 + \cdots + p_r = 1$. Muestra que para $k < r$, $X_1 + X_2 + \cdots X_r$ tiene una distribuci\'on binomial.


\item

\begin{enumerate}
	\item Si una variable aleatoria $T$ tiene una distribuci\'on geom\'etrica, entonces
	
	\[
	\mathbb{P}(T > n + m | T >n) = \mathbb{P}(T > m).
	\]
	
	para todo $n$ y $m$.
	
	\item Muestra el caso contrario: Si $T$ es una variable aleatoria discreta es tal que
	\[
	\mathbb{P}(T > n + m | T >n) = \mathbb{P}(T > m).
	\]
	
	para todo $n, m \in \mathbb{N}$, entonces $T$ tiene una distribuci\'on geom\'etrica.	
	
\end{enumerate}
\item
\begin{enumerate}
\item Supongamos que para un ensayo Bernoulli, $p$, la probabilidad de \'exito es desconocida. Sea $\varepsilon >0 $ y $\alpha >0 $. Prueba que el valor de esta probabilidad se al menos $1 - \alpha$, de que el error estimado sea menor que $\varepsilon$.
\item Para una moneda $p$, la probabilidad de conseguir cara  es desconocida. Para estimar $p$,  lanzamos la moneda $3000$ veces y sea $\hat{p}$  la fracci\'on de veces que cae cara hacia arriba. Demuestra  que la probabilidad  de que al menos $0.90$ que  $\hat{p}$ estima  $p$ p est\'a en $\pm 0,03$.
\end{enumerate}


\item Sean $X$ y $Y$ variables que toman valores sobre $\{0, 1, 2, \dots \}$ tal que $X = Y + Z$ donde $Z$ es una variable aleatoria de Bernoulli con param\'etro $p \in (0, 1)$ independiente de $Y$. S\'olo una de las siguientes aseveraciones es verdad. ?` Cu\'al es ?

\begin{enumerate}
	\item $X + Z$ y $Y + Z$ son independientes.
	\item $X$ tiene los valores $2\mathbb{N}_{0} = \{ 0, 2, 4, \dots\}$.
	\item El soporte de $Y$ es un subconjunto del soporte de $X$.
	\item $\mathbb{E}[( X+ Y)Z] = \mathbb{E}[(X +Y)]\mathbb{E}(Z)$
\end{enumerate}
\item Se dice que una variable aleatoria $X$ es discreta si existe un conjunto finito o contable $S \subset \mathbb{R}$ tal que $\mathbb{P}(X \in S)  = 1$. El conjunto $S$ m\'as peque\~no con esa propiedad se llama \textit{soporte } de $X$.

Si $X$ y $Y$ son variables aleatorias de Bernoulli con el mismo param\'etro $p = \frac{1}{2}$. ?` Puede el soporte de su suma ser igual a $\{0, 1\}$. ?`Qu\'e sucede  en el caso en que $p$ no es necesariamente  igual a $p = \frac{1}{2}$?.


\item Suponiendo que $f:[0,1] \rightarrow [0,1]$ es una funci\'on continua. Muestra un \texttt{m\'etodo probabilistico } para evaluar $\bigintsss_{0}^{1}f(x) dx$, usando la \textit{Ley Fuerte de los Grandes N\'umeros}.

\item Sea $X_1, X_2, \dots $ una secuencia de variables aleatorias con funciones de distribuci\'on $F_1, F_2, \dots$ y las funciones generadoras de momentos $M_{X_1}(t), M_{X_2}(t), \dots$ respectivamente. Sea $X$ una variable aleatoria con funci\'on de distribuci\'on $F$ y funci\'on generadora de momentos $M_X(t)$.

Si para todos los valores de $t$, $M_{X_n}(t)$ converge a $M_{X}(t)$ entonces en los puntos de continuidad de $F$, $F_n$ converge a $F$.



\item Resuelve lo siguiente

\begin{enumerate}
	\item Prueba que se cumple  $n! \sim \sqrt{2\pi n}n^ne^{-n}$ o lo que es lo mismo
	
	\[
	\lim_{n \rightarrow \infty}\dfrac{n!}{\sqrt{2\pi n}n^ne^{-n}}
	\]
	
	\item Sea $\{X_1, X_2, \dots  \}$ una secuencia de variables aleatorias normal est\'andar independientes. Sea $S_n = X_1^2 + X_2^2 + \cdots X_n^2$. Encuentra
	
	\[
	\lim_{n \rightarrow \infty}\mathbb{P}(S_n \leq n + \sqrt{2n}).
	\] 
\end{enumerate}
\item Sea una secuencia $X_1, X_2, \dots$ de variables aleatoria binarias tomando valores en el conjunto $\{0, 1\}$. Sea $Y$ una variable aleatoria continua que toma valores en $[0, 1]$. Relacionamos $X$ e $Y$ asumiendo que $Y$ es el n\'umero real cuya representaci\'on binaria es $0.X_1X_2X_3\dots$, es decir

\[
Y = \sum_{k = 1}^{\infty}2^{-k}X_k
\]

\begin{enumerate}
	\item Suponiendo que $X_i$ forman un proceso de Bernoulli con param\'etro $\frac{1}{2}$. Muestra que $Y$ es distibuida uniformemente (considera la probabilidad del evento $(i - 1)/2^k < Y < i/2^k$, donde $i$ y $k$ son enteros positivos).
	\item Suponiendo que $Y$ es distibuida uniformemente. Muestra que las $X_i$ forman un proceso de Bernoulli con param\'etro $\frac{1}{2}$.
\end{enumerate}
\item  Un \textit{proceso estoc\'astico} $\{ X_n\}_{n \in \mathbb{N}_0}$ es un \textit{camino aleatorio simple} si

\begin{enumerate}
	\item $X_0 = 0$,
	\item El incremento $X_{n + 1} - X_n$ es independiente de $(X_0, X_1, \dots, X_n)$ para cada $n \in \mathbb{N}_{0}$ y 
	\item  El incremento $X_{n + 1} - X_n$ cumple que
	
	\[
	\PR(X_{n + 1} - X_n = 1) = \PR(X_{n + 1} - X_n = -1) = \frac{1}{2}
	\]
\end{enumerate}

Sea el espacio muestral $\Omega$ :

\[
\Omega = [0, 1] \times [0,1]\times \cdots = [0, 1]^{\infty}
\]

y sea la secuencia  $\omega = (\omega_{0}, \omega_{1}, \omega_{2}, \dots)$ de n\'umeros reales en $[0,1]$, un elemento de $\Omega$. Para $n \in \mathbb{N}_{0}$, sea la funci\'on $\gamma_n: \Omega \rightarrow [0,1]$, definida como

\[
\gamma_{n}(\omega) = \omega_{n}
\]

Para esta secuencia, definimos una nueva secuencia $\{ \xi_{n}\}_{n \in \mathbb{N}} $ de variables aleatorias:

\[
\xi_{n} = \begin{cases}
1 & \gamma \geq \frac{1}{2}\\
-1 & \text{en otros casos}
\end{cases}
\]

Si escribimos 

\[
X_0 = 0, \ \ X_n = \sum_{k = 1}^{n}\xi_{k}, \ \ n\in \mathbb{N}.
\]

\vspace{0.2cm}

Prueba que la secuencia $\{ X_n\}_{n \in \mathbb{N}_{0}}$, definida anteriormente es un \textit{camino aleatorio}.

\item Escribamos una definici\'on m\'as general de \textit{camino aleatorio simple}:

\begin{enumerate}
	\item $X_0 = 0$,
	\item El incremento $X_{n + 1} - X_n$ es independiente de $(X_0, X_1, \dots, X_n)$ para cada $n \in \mathbb{N}$ y 
	\item   la variable aleatoria  $X_{n + 1} - X_n$ toman los valores de $-1$ y $1$ con probabilidad $q = 1 -p $ y $p$. Algunos textos describen esto como que la variable aleatoria tiene la distribuci\'on
	
	\[
	\begin{pmatrix}
	- 1 &  1 \\
	 q & p
	\end{pmatrix}
	\]
	
Y si $p = \frac{1}{2}$, se dice que el camino aleatorio es \texttt{sim\'etrico}.

\vspace{0.3cm}

Prueba lo siguiente: Si $\{ X_n\}_{n \in \mathbb{N}_{0}}$ un camino aleatorio sim\'etrico. Para un $n \in  \mathbb{N}$ el camino aleatorio \texttt{promedio} sobre el intervalo $[0, n]$ es definido por

\[
A_n = \frac{1}{n}\sum_{k = 1}^{n}X_k
\]

\begin{enumerate}
	\item ?` Es $A_n$ un camino aleatorio simple (no necesariamente sim\'etrico)?.
	\item Calcula la covarianza $\text{Cov}(X_k, X_l) = \mathbb{E}[(X_k - \mathbb{E}(X_k))(X_l - \mathbb{E}(X_l))]$, para $k \leq l \in \mathbb{N}$.
	\item Calcula la varianza de $A_n$ para $n \in \mathbb{N}$. 
\end{enumerate}

	
\end{enumerate}
\item Sea $\{ X_n\}_{n \in \mathbb{N}_{0}}$ un camino aleatorio sim\'etrico. ?` Cu\'al es la probabilidad que $X_n$ visite todos los puntos en el conjunto $\{1,2, 3, 4  \}$ al menos una vez durante el intervalo de tiempo $n \in \{ 0, \dots, 10\}$?.

\item Sea $Y_1, Y_2, \dots$ variables aleatorias independientes, id\'enticamente distribuidas que toma valores en $[0, \infty)$. Si se coloca $Z_0 = 0, Z_1 = Y_1, Z_2 = Y_1 + Y_2, \dots$. Si $Z_n$ es el tiempo del n-\'esima llegada a una tienda (el proceso estoc\'astico $\{ Z_n: n \in \mathbb{N}\}$) es llamado \textit{renewal process}. Sea $N_{t}$ el n\'umero de llegadas durante $(0, t]$.

\begin{enumerate}
	\item Muestra que
	
	\[
	\PR(N_t \geq n) = \PR(Z_n \leq t)
	\]
	
	para todo $n \in \mathbb{N}$ y $t \in [0, \infty)$.
	
	\item Muestra que para \textit{casi todo } $\omega$,
	
	\[
	\lim_{t \rightarrow \infty}N_t(\omega) = + \infty
	\]
	
	\item Si $Z_{N_{t}}$ es el tiempo de la \'ultima llegada antes del tiempo $t$ y $Z_{N_{t} + 1}$ es el tiempo de la pr\'oxima  llegada despu\'es  del tiempo $t$. Usa la ley fuerte de los grandes n\'umeros y el resultado anterior para probar que 
	
	\[
	\lim_{t \rightarrow \infty}Z_{N_{t}}/N_{t} = a
	\] 
	
	donde $a$ es el valor esperado de $Y$.
\end{enumerate}
\end{enumerate}

\begin{flushright}
%\\{\bfseries El profesor.}
\footnote{Hecho en \LaTeX}
\end{flushright}

\end{document}
